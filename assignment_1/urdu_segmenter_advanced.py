import re

# ---------- Step 1: Normalize Urdu text ----------
def normalize_text(text):
    text = re.sub(r'\s+', ' ', text)  # remove multiple spaces
    text = text.replace(",", "ØŒ")     # replace English comma with Urdu comma
    text = text.replace("''", "â€™â€™").replace("``", "â€˜â€˜")  # fix quotes

    # Remove spaces before Urdu punctuation
    text = re.sub(r'\s+ØŒ', 'ØŒ', text)
    text = re.sub(r'\s+Û”', 'Û”', text)
    return text.strip()


# ---------- Step 2: Insert full stops before discourse markers ----------
def insert_fullstop_before_markers(text):
    markers = [
        "Ù„ÛŒÚ©Ù†", "Ù…Ú¯Ø±", "Ø§Ø¨", "Ø¢Ø¬", "Ø³Ø§ØªÚ¾ ÛÛŒ", "Ø¯ÙˆØ³Ø±ÛŒ Ø¬Ø§Ù†Ø¨",
        "Ú†Ù†Ø§Ù†Ú†Û", "Ø¢Ø®Ø±Ú©Ø§Ø±", "Ø§Ø³ Ù…ÙˆÙ‚Ø¹Û’ Ù¾Ø±", "Ù„ÛÙ°Ø°Ø§"
    ]
    for m in markers:
        text = re.sub(
            rf'(?<![Û”ØŸ!])\s+({m})',
            r'Û” \1',
            text
        )
    return text


# ---------- Step 3: Urdu Sentence Segmentation ----------
def urdu_sentence_segmenter(text):
    text = normalize_text(text)
    text = insert_fullstop_before_markers(text)

    # Protect quotes (â€˜â€˜ â€¦ â€™â€™ or " â€¦ ")
    protected_quotes = re.findall(r'(â€˜â€˜.*?â€™â€™|".*?")', text)
    replacements = {}
    for i, q in enumerate(protected_quotes):
        key = f"__QUOTE_{i}__"
        replacements[key] = q
        text = text.replace(q, key)

    # Split sentences at Û” ? !
    sentences = re.split(r'([Û”?!])', text)

    # Recombine tokens into full sentences
    final_sentences = []
    buffer = ""
    for token in sentences:
        if not token.strip():
            continue
        buffer += token.strip()
        if token in ["Û”", "?", "!"]:
            if buffer.strip():
                final_sentences.append(buffer.strip())
            buffer = ""
    if buffer.strip():
        final_sentences.append(buffer.strip())

    # Restore protected quotes
    restored = []
    for s in final_sentences:
        for key, q in replacements.items():
            s = s.replace(key, q)
        restored.append(s)

    # ---------- Step 4: Post-processing ----------
    cleaned = []
    for s in restored:
        s = s.replace("ØŒÛ”", "Û”")  # remove duplicate punctuation

        # Weak connectors: merge with previous sentence if too short
        if cleaned and (s.startswith(("Ø§ÙˆØ±", "ØªÙˆ", "Ø§Ø³ÛŒ", "Ø¨Ù„Ú©Û")) or len(s.split()) <= 3):
            cleaned[-1] = cleaned[-1].rstrip("Û”") + " " + s
        else:
            cleaned.append(s)

    # Step 5: Handle run-ons (split at Ú©Û, Ø¬Ø³Û’, Ú†ÙˆÙ†Ú©Û, Ø§Ú¯Ø±Ú†Û only after ÛÛ’)
    refined = []
    for s in cleaned:
        parts = re.split(r'(?<=ÛÛ’)\s+(?=(Ú©Û|Ø¬Ø³Û’|Ú†ÙˆÙ†Ú©Û|Ø§Ú¯Ø±Ú†Û))', s)
        if len(parts) > 1:
            chunk = []
            for p in parts:
                if not p.strip():
                    continue
                if re.match(r'^(Ú©Û|Ø¬Ø³Û’|Ú†ÙˆÙ†Ú©Û|Ø§Ú¯Ø±Ú†Û)', p) and chunk:
                    chunk[-1] = chunk[-1].rstrip("Û”") + "Û”"
                chunk.append(p.strip())
            refined.extend(chunk)
        else:
            refined.append(s)

    # Step 6: Numbers/Dates â†’ split only if followed by Û”?! or discourse marker
    strict_split = []
    for s in refined:
        parts = re.split(r'(?<=\d)(?=\s*(Û”|ØŸ|!| Ù„ÛŒÚ©Ù†| Ù…Ú¯Ø±| Ø§Ø¨| Ø¢Ø¬))', s)
        if len(parts) > 1:
            strict_split.extend([p.strip() for p in parts if p.strip()])
        else:
            strict_split.append(s)
    refined = strict_split

    # Step 7: Drop meaningless fragments (< 3 words)
    final_output = [s for s in refined if len(s.split()) > 2]

    return final_output


# ---------- Step 8: Save + Print Segmented Output ----------
if __name__ == "__main__":
    with open("urdu-corpus.txt", "r", encoding="utf-8") as f:
        text = f.read()

    segmented_sentences = urdu_sentence_segmenter(text)

    # Save to file
    with open("segmented_output.txt", "w", encoding="utf-8") as f:
        for s in segmented_sentences:
            f.write(s + "\n")

    print("\nğŸ‘‰ Full result saved in segmented_output.txt")
